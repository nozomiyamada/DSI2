{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "- create a model that predicts the category of each article by `LogisticRegression`\n",
    "- train data is `matichon.json` that contains about 16K articles of Thai news by Matichon between 2015-2018\n",
    "- X is text of headline or article\n",
    "- y is category (10 labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.corpus import thai_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "- target variable is `category`\n",
    "- `headline` and `article` are untokenized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>article</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>url</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏à‡∏ä‡∏±‡∏î‡πÜ ‡∏Å‡∏±‡∏ö'‡∏ä‡∏π‡∏ß‡∏¥‡∏ó‡∏¢‡πå' ‡∏™‡∏ö‡∏π‡πà ‡∏Ç‡∏±‡∏ô ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ß‡πâ...</td>\n",
       "      <td>‡∏ô‡∏≤‡∏¢‡∏ä‡∏π‡∏ß‡∏¥‡∏ó‡∏¢‡πå ‡∏Å‡∏°‡∏•‡∏ß‡∏¥‡∏®‡∏¥‡∏©‡∏é‡πå ‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤‡∏û‡∏£‡∏£‡∏Ñ‡∏£‡∏±‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢ ...</td>\n",
       "      <td>2015-08-16 10:58:27</td>\n",
       "      <td>politics</td>\n",
       "      <td>https://www.matichon.co.th/politics/news_104</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡∏•‡∏∏‡πâ‡∏ô‡∏ö‡∏≤‡∏ó‡∏ó‡∏∞‡∏•‡∏∏40‡∏ï‡πà‡∏≠‡∏î‡∏≠‡∏•‡∏•‡πå ‡∏õ‡∏•‡∏≤‡∏¢‡∏õ‡∏µ'59 ‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°‡∏Ñ‡πà‡∏≤‡πÄ...</td>\n",
       "      <td>‡πÅ‡∏ö‡∏á‡∏Å‡πå‡∏ã‡∏µ‡πÑ‡∏≠‡πÄ‡∏≠‡πá‡∏°‡∏ö‡∏µ ‡∏ä‡∏µ‡πâ‡∏Å‡∏≤‡∏£‡∏ü‡∏∑‡πâ‡∏ô‡∏ü‡∏π‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à‡∏ï‡∏¥‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏£‡∏≤...</td>\n",
       "      <td>2015-08-26 11:19:03</td>\n",
       "      <td>economy</td>\n",
       "      <td>https://www.matichon.co.th/economy/news_148</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡∏®‡∏≤‡∏•‡∏™‡∏π‡∏á‡πÅ‡∏≠‡∏ü‡∏£‡∏¥‡∏Å‡∏≤‡πÉ‡∏ï‡πâ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏´‡πâ \"‡∏û‡∏¥‡∏™‡∏ï‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏™‡∏ú‡∏¥‡∏î‡∏ê‡∏≤‡∏ô‡∏Ü‡∏≤‡∏ï...</td>\n",
       "      <td>‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏ö‡∏µ‡∏ö‡∏µ‡∏ã‡∏µ ‡∏≠‡∏≠‡∏™‡∏Å‡∏≤‡∏£‡πå ‡∏û‡∏¥‡∏™‡∏ï‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏™ ‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡πà‡∏á‡∏£...</td>\n",
       "      <td>2015-12-04 02:52:25</td>\n",
       "      <td>foreign</td>\n",
       "      <td>https://www.matichon.co.th/foreign/news_247</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡πÅ‡∏°‡πà‡πÅ‡∏î‡∏ô‡∏ú‡∏π‡πâ‡∏î‡∏µ‡∏Æ‡∏∂‡∏î! ‡∏≠‡∏∏‡πâ‡∏°‡∏ó‡πâ‡∏≠‡∏á‡∏•‡∏π‡∏Å‡πÅ‡∏ù‡∏î‡πÅ‡∏°‡πâ‡∏£‡∏π‡πâ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏î ‡∏´‡∏ß‡∏±...</td>\n",
       "      <td>‡πÄ‡∏≠‡πá‡∏°‡∏°‡∏≤ ‡∏•‡∏µ ‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏°‡πà‡∏ä‡∏≤‡∏ß‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡∏ß‡∏±‡∏¢ 32 ‡∏õ‡∏µ ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏≠‡∏∏...</td>\n",
       "      <td>2015-12-04 03:11:37</td>\n",
       "      <td>foreign</td>\n",
       "      <td>https://www.matichon.co.th/foreign/news_268</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"‡∏ú‡∏ö.‡∏™‡∏™.\"‡∏ô‡∏≥‡∏ó‡∏´‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏û‡∏£‡∏∞‡∏≠‡∏á‡∏Ñ‡πå ‡∏™‡∏ß‡∏ô‡∏™‡∏ô‡∏≤‡∏°‡πÄ‡∏ó‡∏¥‡∏î‡∏û‡∏£‡∏∞‡πÄ‡∏Å‡∏µ‡∏¢‡∏£...</td>\n",
       "      <td>‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 3 ‡∏ò.‡∏Ñ. ‡∏ó‡∏µ‡πà‡∏°‡∏ì‡∏ë‡∏•‡∏û‡∏¥‡∏ò‡∏µ‡∏ó‡πâ‡∏≠‡∏á‡∏™‡∏ô‡∏≤‡∏°‡∏´‡∏•‡∏ß‡∏á ‡∏û‡∏•....</td>\n",
       "      <td>2015-12-04 03:38:05</td>\n",
       "      <td>politics</td>\n",
       "      <td>https://www.matichon.co.th/politics/news_295</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16321</th>\n",
       "      <td>'‡∏ä‡∏≤‡∏Ñ‡∏£‡∏¥‡∏ï-‡πÄ‡∏£‡∏¢‡πå' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ã‡∏µ‡πâ‡∏û‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏≠‡πà‡∏≠‡∏ô‡∏£‡∏ß‡∏°‡∏Å‡πä‡∏ß‡∏ô ‡∏á‡∏≤‡∏ô‡∏ô‡∏µ...</td>\n",
       "      <td>‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏ô‡∏¥‡∏ó‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡πÅ‡∏ï‡πà‡πÑ‡∏´‡∏ô‡πÅ‡∏ï‡πà‡πÑ‡∏£ ‡πÅ‡∏ñ‡∏°‡∏û‡∏≠‡∏°‡∏µ‡∏•‡∏π‡∏Å ‡∏Å...</td>\n",
       "      <td>2018-07-05 11:43:53</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>https://www.matichon.co.th/entertainment/news_...</td>\n",
       "      <td>1029324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16322</th>\n",
       "      <td>‡∏™‡∏á‡∏Ç‡∏•‡∏≤‡∏à‡∏±‡∏î‡∏á‡∏≤‡∏ô‡∏™‡∏°‡πÇ‡∏†‡∏ä 176 ‡∏õ‡∏µ ‡∏®‡∏≤‡∏•‡πÄ‡∏à‡πâ‡∏≤‡∏û‡πà‡∏≠‡∏´‡∏•‡∏±‡∏Å‡πÄ‡∏°‡∏∑‡∏≠‡∏á</td>\n",
       "      <td>‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 5 ‡∏Å.‡∏Ñ. ‡∏ô‡∏≤‡∏¢‡∏™‡∏°‡∏®‡∏±‡∏Å‡∏î‡∏¥‡πå ‡∏ï‡∏±‡∏ô‡∏ï‡∏¥‡πÄ‡∏®‡∏£‡∏ì‡∏µ ‡∏ô‡∏≤‡∏¢‡∏Å ‡∏ó‡∏ô.‡∏™...</td>\n",
       "      <td>2018-07-05 10:59:53</td>\n",
       "      <td>region</td>\n",
       "      <td>https://www.matichon.co.th/region/news_1029328</td>\n",
       "      <td>1029328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16323</th>\n",
       "      <td>'‡∏™‡∏°‡∏Ñ‡∏¥‡∏î' ‡∏•‡∏±‡πà‡∏ô ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÅ‡∏Ñ‡πà‡∏™‡∏≤‡∏°‡∏°‡∏¥‡∏ï‡∏£ ‡πÅ‡∏ï‡πà‡∏°‡∏µ‡∏°‡∏ß‡∏•‡∏´‡∏°‡∏π‡πà‡∏°‡∏´‡∏≤‡∏°...</td>\n",
       "      <td>\"‡∏™‡∏°‡∏Ñ‡∏¥‡∏î\" ‡∏•‡∏±‡πà‡∏ô‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÅ‡∏Ñ‡πà‡∏™‡∏≤‡∏°‡∏°‡∏¥‡∏ï‡∏£ ‡πÅ‡∏ï‡πà‡∏°‡∏µ‡∏°‡∏ß‡∏•‡∏´‡∏°‡∏π‡πà‡∏°‡∏´‡∏≤‡∏°‡∏¥...</td>\n",
       "      <td>2018-07-05 12:09:08</td>\n",
       "      <td>politics</td>\n",
       "      <td>https://www.matichon.co.th/politics/news_1029410</td>\n",
       "      <td>1029410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16324</th>\n",
       "      <td>‡∏°.‡∏£‡∏≤‡∏°‡∏Ø‡∏õ‡∏ê‡∏°‡∏ô‡∏¥‡πÄ‡∏ó‡∏® ‡∏ô‡∏®.‡πÉ‡∏´‡∏°‡πà ‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏à‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÉ‡∏´‡πâ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à-‡∏°‡∏µ...</td>\n",
       "      <td>‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏®‡∏≤‡∏™‡∏ï‡∏£‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå‡∏ß‡∏∏‡∏í‡∏¥‡∏®‡∏±‡∏Å‡∏î‡∏¥‡πå  ‡∏•‡∏≤‡∏†‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå ‡∏≠...</td>\n",
       "      <td>2018-07-05 13:45:34</td>\n",
       "      <td>publicize</td>\n",
       "      <td>https://www.matichon.co.th/publicize/news_1029659</td>\n",
       "      <td>1029659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16325</th>\n",
       "      <td>'‡∏ì‡∏£‡∏á‡∏Ñ‡πå‡∏®‡∏±‡∏Å‡∏î‡∏¥‡πå' ‡∏ö‡∏≠‡∏Å‡∏•‡∏≤-‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÑ‡∏•‡∏ô‡πå '‡∏´‡∏ô.‡∏™‡πà‡∏ß‡∏ô‡∏£‡∏≤...</td>\n",
       "      <td>\"‡∏ì‡∏£‡∏á‡∏Ñ‡πå‡∏®‡∏±‡∏Å‡∏î‡∏¥‡πå\" ‡πÑ‡∏•‡∏ô‡πå‡∏•‡∏≤ \"‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î...</td>\n",
       "      <td>2018-07-05 15:36:04</td>\n",
       "      <td>politics</td>\n",
       "      <td>https://www.matichon.co.th/politics/news_1029955</td>\n",
       "      <td>1029955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16326 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  \\\n",
       "0      ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏à‡∏ä‡∏±‡∏î‡πÜ ‡∏Å‡∏±‡∏ö'‡∏ä‡∏π‡∏ß‡∏¥‡∏ó‡∏¢‡πå' ‡∏™‡∏ö‡∏π‡πà ‡∏Ç‡∏±‡∏ô ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ß‡πâ...   \n",
       "1      ‡∏•‡∏∏‡πâ‡∏ô‡∏ö‡∏≤‡∏ó‡∏ó‡∏∞‡∏•‡∏∏40‡∏ï‡πà‡∏≠‡∏î‡∏≠‡∏•‡∏•‡πå ‡∏õ‡∏•‡∏≤‡∏¢‡∏õ‡∏µ'59 ‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°‡∏Ñ‡πà‡∏≤‡πÄ...   \n",
       "2      ‡∏®‡∏≤‡∏•‡∏™‡∏π‡∏á‡πÅ‡∏≠‡∏ü‡∏£‡∏¥‡∏Å‡∏≤‡πÉ‡∏ï‡πâ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏´‡πâ \"‡∏û‡∏¥‡∏™‡∏ï‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏™‡∏ú‡∏¥‡∏î‡∏ê‡∏≤‡∏ô‡∏Ü‡∏≤‡∏ï...   \n",
       "3      ‡πÅ‡∏°‡πà‡πÅ‡∏î‡∏ô‡∏ú‡∏π‡πâ‡∏î‡∏µ‡∏Æ‡∏∂‡∏î! ‡∏≠‡∏∏‡πâ‡∏°‡∏ó‡πâ‡∏≠‡∏á‡∏•‡∏π‡∏Å‡πÅ‡∏ù‡∏î‡πÅ‡∏°‡πâ‡∏£‡∏π‡πâ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏î ‡∏´‡∏ß‡∏±...   \n",
       "4      \"‡∏ú‡∏ö.‡∏™‡∏™.\"‡∏ô‡∏≥‡∏ó‡∏´‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏û‡∏£‡∏∞‡∏≠‡∏á‡∏Ñ‡πå ‡∏™‡∏ß‡∏ô‡∏™‡∏ô‡∏≤‡∏°‡πÄ‡∏ó‡∏¥‡∏î‡∏û‡∏£‡∏∞‡πÄ‡∏Å‡∏µ‡∏¢‡∏£...   \n",
       "...                                                  ...   \n",
       "16321  '‡∏ä‡∏≤‡∏Ñ‡∏£‡∏¥‡∏ï-‡πÄ‡∏£‡∏¢‡πå' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ã‡∏µ‡πâ‡∏û‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏≠‡πà‡∏≠‡∏ô‡∏£‡∏ß‡∏°‡∏Å‡πä‡∏ß‡∏ô ‡∏á‡∏≤‡∏ô‡∏ô‡∏µ...   \n",
       "16322        ‡∏™‡∏á‡∏Ç‡∏•‡∏≤‡∏à‡∏±‡∏î‡∏á‡∏≤‡∏ô‡∏™‡∏°‡πÇ‡∏†‡∏ä 176 ‡∏õ‡∏µ ‡∏®‡∏≤‡∏•‡πÄ‡∏à‡πâ‡∏≤‡∏û‡πà‡∏≠‡∏´‡∏•‡∏±‡∏Å‡πÄ‡∏°‡∏∑‡∏≠‡∏á   \n",
       "16323  '‡∏™‡∏°‡∏Ñ‡∏¥‡∏î' ‡∏•‡∏±‡πà‡∏ô ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÅ‡∏Ñ‡πà‡∏™‡∏≤‡∏°‡∏°‡∏¥‡∏ï‡∏£ ‡πÅ‡∏ï‡πà‡∏°‡∏µ‡∏°‡∏ß‡∏•‡∏´‡∏°‡∏π‡πà‡∏°‡∏´‡∏≤‡∏°...   \n",
       "16324  ‡∏°.‡∏£‡∏≤‡∏°‡∏Ø‡∏õ‡∏ê‡∏°‡∏ô‡∏¥‡πÄ‡∏ó‡∏® ‡∏ô‡∏®.‡πÉ‡∏´‡∏°‡πà ‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏à‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÉ‡∏´‡πâ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à-‡∏°‡∏µ...   \n",
       "16325  '‡∏ì‡∏£‡∏á‡∏Ñ‡πå‡∏®‡∏±‡∏Å‡∏î‡∏¥‡πå' ‡∏ö‡∏≠‡∏Å‡∏•‡∏≤-‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÑ‡∏•‡∏ô‡πå '‡∏´‡∏ô.‡∏™‡πà‡∏ß‡∏ô‡∏£‡∏≤...   \n",
       "\n",
       "                                                 article                date  \\\n",
       "0      ‡∏ô‡∏≤‡∏¢‡∏ä‡∏π‡∏ß‡∏¥‡∏ó‡∏¢‡πå ‡∏Å‡∏°‡∏•‡∏ß‡∏¥‡∏®‡∏¥‡∏©‡∏é‡πå ‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤‡∏û‡∏£‡∏£‡∏Ñ‡∏£‡∏±‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢ ... 2015-08-16 10:58:27   \n",
       "1      ‡πÅ‡∏ö‡∏á‡∏Å‡πå‡∏ã‡∏µ‡πÑ‡∏≠‡πÄ‡∏≠‡πá‡∏°‡∏ö‡∏µ ‡∏ä‡∏µ‡πâ‡∏Å‡∏≤‡∏£‡∏ü‡∏∑‡πâ‡∏ô‡∏ü‡∏π‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à‡∏ï‡∏¥‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏£‡∏≤... 2015-08-26 11:19:03   \n",
       "2      ‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏ö‡∏µ‡∏ö‡∏µ‡∏ã‡∏µ ‡∏≠‡∏≠‡∏™‡∏Å‡∏≤‡∏£‡πå ‡∏û‡∏¥‡∏™‡∏ï‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏™ ‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡πà‡∏á‡∏£... 2015-12-04 02:52:25   \n",
       "3      ‡πÄ‡∏≠‡πá‡∏°‡∏°‡∏≤ ‡∏•‡∏µ ‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏°‡πà‡∏ä‡∏≤‡∏ß‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡∏ß‡∏±‡∏¢ 32 ‡∏õ‡∏µ ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏≠‡∏∏... 2015-12-04 03:11:37   \n",
       "4      ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 3 ‡∏ò.‡∏Ñ. ‡∏ó‡∏µ‡πà‡∏°‡∏ì‡∏ë‡∏•‡∏û‡∏¥‡∏ò‡∏µ‡∏ó‡πâ‡∏≠‡∏á‡∏™‡∏ô‡∏≤‡∏°‡∏´‡∏•‡∏ß‡∏á ‡∏û‡∏•.... 2015-12-04 03:38:05   \n",
       "...                                                  ...                 ...   \n",
       "16321  ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏ô‡∏¥‡∏ó‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡πÅ‡∏ï‡πà‡πÑ‡∏´‡∏ô‡πÅ‡∏ï‡πà‡πÑ‡∏£ ‡πÅ‡∏ñ‡∏°‡∏û‡∏≠‡∏°‡∏µ‡∏•‡∏π‡∏Å ‡∏Å... 2018-07-05 11:43:53   \n",
       "16322  ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 5 ‡∏Å.‡∏Ñ. ‡∏ô‡∏≤‡∏¢‡∏™‡∏°‡∏®‡∏±‡∏Å‡∏î‡∏¥‡πå ‡∏ï‡∏±‡∏ô‡∏ï‡∏¥‡πÄ‡∏®‡∏£‡∏ì‡∏µ ‡∏ô‡∏≤‡∏¢‡∏Å ‡∏ó‡∏ô.‡∏™... 2018-07-05 10:59:53   \n",
       "16323  \"‡∏™‡∏°‡∏Ñ‡∏¥‡∏î\" ‡∏•‡∏±‡πà‡∏ô‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÅ‡∏Ñ‡πà‡∏™‡∏≤‡∏°‡∏°‡∏¥‡∏ï‡∏£ ‡πÅ‡∏ï‡πà‡∏°‡∏µ‡∏°‡∏ß‡∏•‡∏´‡∏°‡∏π‡πà‡∏°‡∏´‡∏≤‡∏°‡∏¥... 2018-07-05 12:09:08   \n",
       "16324  ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏®‡∏≤‡∏™‡∏ï‡∏£‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå‡∏ß‡∏∏‡∏í‡∏¥‡∏®‡∏±‡∏Å‡∏î‡∏¥‡πå  ‡∏•‡∏≤‡∏†‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå ‡∏≠... 2018-07-05 13:45:34   \n",
       "16325  \"‡∏ì‡∏£‡∏á‡∏Ñ‡πå‡∏®‡∏±‡∏Å‡∏î‡∏¥‡πå\" ‡πÑ‡∏•‡∏ô‡πå‡∏•‡∏≤ \"‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î... 2018-07-05 15:36:04   \n",
       "\n",
       "            category                                                url  \\\n",
       "0           politics       https://www.matichon.co.th/politics/news_104   \n",
       "1            economy        https://www.matichon.co.th/economy/news_148   \n",
       "2            foreign        https://www.matichon.co.th/foreign/news_247   \n",
       "3            foreign        https://www.matichon.co.th/foreign/news_268   \n",
       "4           politics       https://www.matichon.co.th/politics/news_295   \n",
       "...              ...                                                ...   \n",
       "16321  entertainment  https://www.matichon.co.th/entertainment/news_...   \n",
       "16322         region     https://www.matichon.co.th/region/news_1029328   \n",
       "16323       politics   https://www.matichon.co.th/politics/news_1029410   \n",
       "16324      publicize  https://www.matichon.co.th/publicize/news_1029659   \n",
       "16325       politics   https://www.matichon.co.th/politics/news_1029955   \n",
       "\n",
       "            id  \n",
       "0          104  \n",
       "1          148  \n",
       "2          247  \n",
       "3          268  \n",
       "4          295  \n",
       "...        ...  \n",
       "16321  1029324  \n",
       "16322  1029328  \n",
       "16323  1029410  \n",
       "16324  1029659  \n",
       "16325  1029955  \n",
       "\n",
       "[16326 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('data/matichon.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>article</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏à‡∏ä‡∏±‡∏î‡πÜ ‡∏Å‡∏±‡∏ö'‡∏ä‡∏π‡∏ß‡∏¥‡∏ó‡∏¢‡πå' ‡∏™‡∏ö‡∏π‡πà ‡∏Ç‡∏±‡∏ô ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ß‡πâ...</td>\n",
       "      <td>‡∏ô‡∏≤‡∏¢‡∏ä‡∏π‡∏ß‡∏¥‡∏ó‡∏¢‡πå ‡∏Å‡∏°‡∏•‡∏ß‡∏¥‡∏®‡∏¥‡∏©‡∏é‡πå ‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤‡∏û‡∏£‡∏£‡∏Ñ‡∏£‡∏±‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢ ...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡∏•‡∏∏‡πâ‡∏ô‡∏ö‡∏≤‡∏ó‡∏ó‡∏∞‡∏•‡∏∏40‡∏ï‡πà‡∏≠‡∏î‡∏≠‡∏•‡∏•‡πå ‡∏õ‡∏•‡∏≤‡∏¢‡∏õ‡∏µ'59 ‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°‡∏Ñ‡πà‡∏≤‡πÄ...</td>\n",
       "      <td>‡πÅ‡∏ö‡∏á‡∏Å‡πå‡∏ã‡∏µ‡πÑ‡∏≠‡πÄ‡∏≠‡πá‡∏°‡∏ö‡∏µ ‡∏ä‡∏µ‡πâ‡∏Å‡∏≤‡∏£‡∏ü‡∏∑‡πâ‡∏ô‡∏ü‡∏π‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à‡∏ï‡∏¥‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏£‡∏≤...</td>\n",
       "      <td>economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡∏®‡∏≤‡∏•‡∏™‡∏π‡∏á‡πÅ‡∏≠‡∏ü‡∏£‡∏¥‡∏Å‡∏≤‡πÉ‡∏ï‡πâ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏´‡πâ \"‡∏û‡∏¥‡∏™‡∏ï‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏™‡∏ú‡∏¥‡∏î‡∏ê‡∏≤‡∏ô‡∏Ü‡∏≤‡∏ï...</td>\n",
       "      <td>‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏ö‡∏µ‡∏ö‡∏µ‡∏ã‡∏µ ‡∏≠‡∏≠‡∏™‡∏Å‡∏≤‡∏£‡πå ‡∏û‡∏¥‡∏™‡∏ï‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏™ ‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡πà‡∏á‡∏£...</td>\n",
       "      <td>foreign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡πÅ‡∏°‡πà‡πÅ‡∏î‡∏ô‡∏ú‡∏π‡πâ‡∏î‡∏µ‡∏Æ‡∏∂‡∏î! ‡∏≠‡∏∏‡πâ‡∏°‡∏ó‡πâ‡∏≠‡∏á‡∏•‡∏π‡∏Å‡πÅ‡∏ù‡∏î‡πÅ‡∏°‡πâ‡∏£‡∏π‡πâ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏î ‡∏´‡∏ß‡∏±...</td>\n",
       "      <td>‡πÄ‡∏≠‡πá‡∏°‡∏°‡∏≤ ‡∏•‡∏µ ‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏°‡πà‡∏ä‡∏≤‡∏ß‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡∏ß‡∏±‡∏¢ 32 ‡∏õ‡∏µ ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏≠‡∏∏...</td>\n",
       "      <td>foreign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"‡∏ú‡∏ö.‡∏™‡∏™.\"‡∏ô‡∏≥‡∏ó‡∏´‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏û‡∏£‡∏∞‡∏≠‡∏á‡∏Ñ‡πå ‡∏™‡∏ß‡∏ô‡∏™‡∏ô‡∏≤‡∏°‡πÄ‡∏ó‡∏¥‡∏î‡∏û‡∏£‡∏∞‡πÄ‡∏Å‡∏µ‡∏¢‡∏£...</td>\n",
       "      <td>‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 3 ‡∏ò.‡∏Ñ. ‡∏ó‡∏µ‡πà‡∏°‡∏ì‡∏ë‡∏•‡∏û‡∏¥‡∏ò‡∏µ‡∏ó‡πâ‡∏≠‡∏á‡∏™‡∏ô‡∏≤‡∏°‡∏´‡∏•‡∏ß‡∏á ‡∏û‡∏•....</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏à‡∏ä‡∏±‡∏î‡πÜ ‡∏Å‡∏±‡∏ö'‡∏ä‡∏π‡∏ß‡∏¥‡∏ó‡∏¢‡πå' ‡∏™‡∏ö‡∏π‡πà ‡∏Ç‡∏±‡∏ô ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ß‡πâ...   \n",
       "1  ‡∏•‡∏∏‡πâ‡∏ô‡∏ö‡∏≤‡∏ó‡∏ó‡∏∞‡∏•‡∏∏40‡∏ï‡πà‡∏≠‡∏î‡∏≠‡∏•‡∏•‡πå ‡∏õ‡∏•‡∏≤‡∏¢‡∏õ‡∏µ'59 ‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°‡∏Ñ‡πà‡∏≤‡πÄ...   \n",
       "2  ‡∏®‡∏≤‡∏•‡∏™‡∏π‡∏á‡πÅ‡∏≠‡∏ü‡∏£‡∏¥‡∏Å‡∏≤‡πÉ‡∏ï‡πâ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏´‡πâ \"‡∏û‡∏¥‡∏™‡∏ï‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏™‡∏ú‡∏¥‡∏î‡∏ê‡∏≤‡∏ô‡∏Ü‡∏≤‡∏ï...   \n",
       "3  ‡πÅ‡∏°‡πà‡πÅ‡∏î‡∏ô‡∏ú‡∏π‡πâ‡∏î‡∏µ‡∏Æ‡∏∂‡∏î! ‡∏≠‡∏∏‡πâ‡∏°‡∏ó‡πâ‡∏≠‡∏á‡∏•‡∏π‡∏Å‡πÅ‡∏ù‡∏î‡πÅ‡∏°‡πâ‡∏£‡∏π‡πâ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏î ‡∏´‡∏ß‡∏±...   \n",
       "4  \"‡∏ú‡∏ö.‡∏™‡∏™.\"‡∏ô‡∏≥‡∏ó‡∏´‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏û‡∏£‡∏∞‡∏≠‡∏á‡∏Ñ‡πå ‡∏™‡∏ß‡∏ô‡∏™‡∏ô‡∏≤‡∏°‡πÄ‡∏ó‡∏¥‡∏î‡∏û‡∏£‡∏∞‡πÄ‡∏Å‡∏µ‡∏¢‡∏£...   \n",
       "\n",
       "                                             article  category  \n",
       "0  ‡∏ô‡∏≤‡∏¢‡∏ä‡∏π‡∏ß‡∏¥‡∏ó‡∏¢‡πå ‡∏Å‡∏°‡∏•‡∏ß‡∏¥‡∏®‡∏¥‡∏©‡∏é‡πå ‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤‡∏û‡∏£‡∏£‡∏Ñ‡∏£‡∏±‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢ ...  politics  \n",
       "1  ‡πÅ‡∏ö‡∏á‡∏Å‡πå‡∏ã‡∏µ‡πÑ‡∏≠‡πÄ‡∏≠‡πá‡∏°‡∏ö‡∏µ ‡∏ä‡∏µ‡πâ‡∏Å‡∏≤‡∏£‡∏ü‡∏∑‡πâ‡∏ô‡∏ü‡∏π‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à‡∏ï‡∏¥‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏£‡∏≤...   economy  \n",
       "2  ‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏ö‡∏µ‡∏ö‡∏µ‡∏ã‡∏µ ‡∏≠‡∏≠‡∏™‡∏Å‡∏≤‡∏£‡πå ‡∏û‡∏¥‡∏™‡∏ï‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏™ ‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡πà‡∏á‡∏£...   foreign  \n",
       "3  ‡πÄ‡∏≠‡πá‡∏°‡∏°‡∏≤ ‡∏•‡∏µ ‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏°‡πà‡∏ä‡∏≤‡∏ß‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡∏ß‡∏±‡∏¢ 32 ‡∏õ‡∏µ ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏≠‡∏∏...   foreign  \n",
       "4  ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 3 ‡∏ò.‡∏Ñ. ‡∏ó‡∏µ‡πà‡∏°‡∏ì‡∏ë‡∏•‡∏û‡∏¥‡∏ò‡∏µ‡∏ó‡πâ‡∏≠‡∏á‡∏™‡∏ô‡∏≤‡∏°‡∏´‡∏•‡∏ß‡∏á ‡∏û‡∏•....  politics  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## drop \"date\", \"url\", and \"id\"\n",
    "df = df.drop(columns=['date','url','id'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "politics         3008\n",
       "region           2703\n",
       "crime            2053\n",
       "local            1706\n",
       "publicize        1466\n",
       "foreign          1225\n",
       "sport            1193\n",
       "economy          1158\n",
       "education         936\n",
       "entertainment     878\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## value counts of target variable\n",
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize & train-test split\n",
    "\n",
    "- it may take more than 2 minutes\n",
    "- you can save the tokenized file by `df.to_json('XXX.json', orient='records')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['headline_tokens'] = df.headline.apply(word_tokenize)\n",
    "df['article_tokens'] = df.article.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>article</th>\n",
       "      <th>category</th>\n",
       "      <th>headline_tokens</th>\n",
       "      <th>article_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏à‡∏ä‡∏±‡∏î‡πÜ ‡∏Å‡∏±‡∏ö'‡∏ä‡∏π‡∏ß‡∏¥‡∏ó‡∏¢‡πå' ‡∏™‡∏ö‡∏π‡πà ‡∏Ç‡∏±‡∏ô ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ß‡πâ...</td>\n",
       "      <td>‡∏ô‡∏≤‡∏¢‡∏ä‡∏π‡∏ß‡∏¥‡∏ó‡∏¢‡πå ‡∏Å‡∏°‡∏•‡∏ß‡∏¥‡∏®‡∏¥‡∏©‡∏é‡πå ‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤‡∏û‡∏£‡∏£‡∏Ñ‡∏£‡∏±‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢ ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>[‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏à, ‡∏ä‡∏±‡∏î, ‡πÜ,  , ‡∏Å‡∏±‡∏ö, ', ‡∏ä‡∏π, ‡∏ß‡∏¥‡∏ó‡∏¢‡πå, ',  , ‡∏™...</td>\n",
       "      <td>[‡∏ô‡∏≤‡∏¢, ‡∏ä‡∏π, ‡∏ß‡∏¥‡∏ó‡∏¢‡πå,  , ‡∏Å‡∏°‡∏•, ‡∏ß‡∏¥, ‡∏®‡∏¥‡∏©‡∏é‡πå,  , ‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡∏•‡∏∏‡πâ‡∏ô‡∏ö‡∏≤‡∏ó‡∏ó‡∏∞‡∏•‡∏∏40‡∏ï‡πà‡∏≠‡∏î‡∏≠‡∏•‡∏•‡πå ‡∏õ‡∏•‡∏≤‡∏¢‡∏õ‡∏µ'59 ‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°‡∏Ñ‡πà‡∏≤‡πÄ...</td>\n",
       "      <td>‡πÅ‡∏ö‡∏á‡∏Å‡πå‡∏ã‡∏µ‡πÑ‡∏≠‡πÄ‡∏≠‡πá‡∏°‡∏ö‡∏µ ‡∏ä‡∏µ‡πâ‡∏Å‡∏≤‡∏£‡∏ü‡∏∑‡πâ‡∏ô‡∏ü‡∏π‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à‡∏ï‡∏¥‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏£‡∏≤...</td>\n",
       "      <td>economy</td>\n",
       "      <td>[‡∏•‡∏∏‡πâ‡∏ô, ‡∏ö‡∏≤‡∏ó, ‡∏ó‡∏∞‡∏•‡∏∏, 40, ‡∏ï‡πà‡∏≠, ‡∏î‡∏≠‡∏•‡∏•‡πå,  , ‡∏õ‡∏•‡∏≤‡∏¢‡∏õ‡∏µ, '...</td>\n",
       "      <td>[‡πÅ‡∏ö‡∏á‡∏Å‡πå, ‡∏ã‡∏µ, ‡πÑ‡∏≠, ‡πÄ‡∏≠‡πá‡∏°, ‡∏ö‡∏µ,  , ‡∏ä‡∏µ‡πâ, ‡∏Å‡∏≤‡∏£‡∏ü‡∏∑‡πâ‡∏ô‡∏ü‡∏π, ‡πÄ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡∏®‡∏≤‡∏•‡∏™‡∏π‡∏á‡πÅ‡∏≠‡∏ü‡∏£‡∏¥‡∏Å‡∏≤‡πÉ‡∏ï‡πâ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏´‡πâ \"‡∏û‡∏¥‡∏™‡∏ï‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏™‡∏ú‡∏¥‡∏î‡∏ê‡∏≤‡∏ô‡∏Ü‡∏≤‡∏ï...</td>\n",
       "      <td>‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏ö‡∏µ‡∏ö‡∏µ‡∏ã‡∏µ ‡∏≠‡∏≠‡∏™‡∏Å‡∏≤‡∏£‡πå ‡∏û‡∏¥‡∏™‡∏ï‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏™ ‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡πà‡∏á‡∏£...</td>\n",
       "      <td>foreign</td>\n",
       "      <td>[‡∏®‡∏≤‡∏•‡∏™‡∏π‡∏á, ‡πÅ‡∏≠‡∏ü‡∏£‡∏¥‡∏Å‡∏≤‡πÉ‡∏ï‡πâ, ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô, ‡πÉ‡∏´‡πâ,  , \"‡∏û‡∏¥, ‡∏™‡∏ï‡∏≠,...</td>\n",
       "      <td>[‡∏à‡∏≤‡∏Å, ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô, ‡∏Ç‡∏≠‡∏á, ‡∏ö‡∏µ‡∏ö‡∏µ‡∏ã‡∏µ,  , ‡∏≠‡∏≠‡∏™‡∏Å‡∏≤‡∏£‡πå,  , ‡∏û‡∏¥, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡πÅ‡∏°‡πà‡πÅ‡∏î‡∏ô‡∏ú‡∏π‡πâ‡∏î‡∏µ‡∏Æ‡∏∂‡∏î! ‡∏≠‡∏∏‡πâ‡∏°‡∏ó‡πâ‡∏≠‡∏á‡∏•‡∏π‡∏Å‡πÅ‡∏ù‡∏î‡πÅ‡∏°‡πâ‡∏£‡∏π‡πâ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏î ‡∏´‡∏ß‡∏±...</td>\n",
       "      <td>‡πÄ‡∏≠‡πá‡∏°‡∏°‡∏≤ ‡∏•‡∏µ ‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏°‡πà‡∏ä‡∏≤‡∏ß‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡∏ß‡∏±‡∏¢ 32 ‡∏õ‡∏µ ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏≠‡∏∏...</td>\n",
       "      <td>foreign</td>\n",
       "      <td>[‡πÅ‡∏°‡πà, ‡πÅ‡∏î‡∏ô, ‡∏ú‡∏π‡πâ‡∏î‡∏µ, ‡∏Æ‡∏∂‡∏î, !,  , ‡∏≠‡∏∏‡πâ‡∏°‡∏ó‡πâ‡∏≠‡∏á, ‡∏•‡∏π‡∏Å‡πÅ‡∏ù‡∏î,...</td>\n",
       "      <td>[‡πÄ‡∏≠‡πá‡∏°, ‡∏°‡∏≤,  , ‡∏•‡∏µ,  , ‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏°‡πà, ‡∏ä‡∏≤‡∏ß, ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©,  , ‡∏ß...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"‡∏ú‡∏ö.‡∏™‡∏™.\"‡∏ô‡∏≥‡∏ó‡∏´‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏û‡∏£‡∏∞‡∏≠‡∏á‡∏Ñ‡πå ‡∏™‡∏ß‡∏ô‡∏™‡∏ô‡∏≤‡∏°‡πÄ‡∏ó‡∏¥‡∏î‡∏û‡∏£‡∏∞‡πÄ‡∏Å‡∏µ‡∏¢‡∏£...</td>\n",
       "      <td>‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 3 ‡∏ò.‡∏Ñ. ‡∏ó‡∏µ‡πà‡∏°‡∏ì‡∏ë‡∏•‡∏û‡∏¥‡∏ò‡∏µ‡∏ó‡πâ‡∏≠‡∏á‡∏™‡∏ô‡∏≤‡∏°‡∏´‡∏•‡∏ß‡∏á ‡∏û‡∏•....</td>\n",
       "      <td>politics</td>\n",
       "      <td>[\", ‡∏ú‡∏ö.‡∏™‡∏™., \", ‡∏ô‡∏≥, ‡∏ó‡∏´‡∏≤‡∏£, ‡∏£‡∏±‡∏Å‡∏©‡∏≤, ‡∏û‡∏£‡∏∞‡∏≠‡∏á‡∏Ñ‡πå,  , ‡∏™‡∏ß...</td>\n",
       "      <td>[‡πÄ‡∏°‡∏∑‡πà‡∏≠, ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà,  , 3,  , ‡∏ò.‡∏Ñ.,  , ‡∏ó‡∏µ‡πà, ‡∏°‡∏ì‡∏ë‡∏•, ‡∏û...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏à‡∏ä‡∏±‡∏î‡πÜ ‡∏Å‡∏±‡∏ö'‡∏ä‡∏π‡∏ß‡∏¥‡∏ó‡∏¢‡πå' ‡∏™‡∏ö‡∏π‡πà ‡∏Ç‡∏±‡∏ô ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ß‡πâ...   \n",
       "1  ‡∏•‡∏∏‡πâ‡∏ô‡∏ö‡∏≤‡∏ó‡∏ó‡∏∞‡∏•‡∏∏40‡∏ï‡πà‡∏≠‡∏î‡∏≠‡∏•‡∏•‡πå ‡∏õ‡∏•‡∏≤‡∏¢‡∏õ‡∏µ'59 ‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°‡∏Ñ‡πà‡∏≤‡πÄ...   \n",
       "2  ‡∏®‡∏≤‡∏•‡∏™‡∏π‡∏á‡πÅ‡∏≠‡∏ü‡∏£‡∏¥‡∏Å‡∏≤‡πÉ‡∏ï‡πâ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏´‡πâ \"‡∏û‡∏¥‡∏™‡∏ï‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏™‡∏ú‡∏¥‡∏î‡∏ê‡∏≤‡∏ô‡∏Ü‡∏≤‡∏ï...   \n",
       "3  ‡πÅ‡∏°‡πà‡πÅ‡∏î‡∏ô‡∏ú‡∏π‡πâ‡∏î‡∏µ‡∏Æ‡∏∂‡∏î! ‡∏≠‡∏∏‡πâ‡∏°‡∏ó‡πâ‡∏≠‡∏á‡∏•‡∏π‡∏Å‡πÅ‡∏ù‡∏î‡πÅ‡∏°‡πâ‡∏£‡∏π‡πâ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏î ‡∏´‡∏ß‡∏±...   \n",
       "4  \"‡∏ú‡∏ö.‡∏™‡∏™.\"‡∏ô‡∏≥‡∏ó‡∏´‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏û‡∏£‡∏∞‡∏≠‡∏á‡∏Ñ‡πå ‡∏™‡∏ß‡∏ô‡∏™‡∏ô‡∏≤‡∏°‡πÄ‡∏ó‡∏¥‡∏î‡∏û‡∏£‡∏∞‡πÄ‡∏Å‡∏µ‡∏¢‡∏£...   \n",
       "\n",
       "                                             article  category  \\\n",
       "0  ‡∏ô‡∏≤‡∏¢‡∏ä‡∏π‡∏ß‡∏¥‡∏ó‡∏¢‡πå ‡∏Å‡∏°‡∏•‡∏ß‡∏¥‡∏®‡∏¥‡∏©‡∏é‡πå ‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤‡∏û‡∏£‡∏£‡∏Ñ‡∏£‡∏±‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢ ...  politics   \n",
       "1  ‡πÅ‡∏ö‡∏á‡∏Å‡πå‡∏ã‡∏µ‡πÑ‡∏≠‡πÄ‡∏≠‡πá‡∏°‡∏ö‡∏µ ‡∏ä‡∏µ‡πâ‡∏Å‡∏≤‡∏£‡∏ü‡∏∑‡πâ‡∏ô‡∏ü‡∏π‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à‡∏ï‡∏¥‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏£‡∏≤...   economy   \n",
       "2  ‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏ö‡∏µ‡∏ö‡∏µ‡∏ã‡∏µ ‡∏≠‡∏≠‡∏™‡∏Å‡∏≤‡∏£‡πå ‡∏û‡∏¥‡∏™‡∏ï‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏™ ‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡πà‡∏á‡∏£...   foreign   \n",
       "3  ‡πÄ‡∏≠‡πá‡∏°‡∏°‡∏≤ ‡∏•‡∏µ ‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏°‡πà‡∏ä‡∏≤‡∏ß‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡∏ß‡∏±‡∏¢ 32 ‡∏õ‡∏µ ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏≠‡∏∏...   foreign   \n",
       "4  ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 3 ‡∏ò.‡∏Ñ. ‡∏ó‡∏µ‡πà‡∏°‡∏ì‡∏ë‡∏•‡∏û‡∏¥‡∏ò‡∏µ‡∏ó‡πâ‡∏≠‡∏á‡∏™‡∏ô‡∏≤‡∏°‡∏´‡∏•‡∏ß‡∏á ‡∏û‡∏•....  politics   \n",
       "\n",
       "                                     headline_tokens  \\\n",
       "0  [‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏à, ‡∏ä‡∏±‡∏î, ‡πÜ,  , ‡∏Å‡∏±‡∏ö, ', ‡∏ä‡∏π, ‡∏ß‡∏¥‡∏ó‡∏¢‡πå, ',  , ‡∏™...   \n",
       "1  [‡∏•‡∏∏‡πâ‡∏ô, ‡∏ö‡∏≤‡∏ó, ‡∏ó‡∏∞‡∏•‡∏∏, 40, ‡∏ï‡πà‡∏≠, ‡∏î‡∏≠‡∏•‡∏•‡πå,  , ‡∏õ‡∏•‡∏≤‡∏¢‡∏õ‡∏µ, '...   \n",
       "2  [‡∏®‡∏≤‡∏•‡∏™‡∏π‡∏á, ‡πÅ‡∏≠‡∏ü‡∏£‡∏¥‡∏Å‡∏≤‡πÉ‡∏ï‡πâ, ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô, ‡πÉ‡∏´‡πâ,  , \"‡∏û‡∏¥, ‡∏™‡∏ï‡∏≠,...   \n",
       "3  [‡πÅ‡∏°‡πà, ‡πÅ‡∏î‡∏ô, ‡∏ú‡∏π‡πâ‡∏î‡∏µ, ‡∏Æ‡∏∂‡∏î, !,  , ‡∏≠‡∏∏‡πâ‡∏°‡∏ó‡πâ‡∏≠‡∏á, ‡∏•‡∏π‡∏Å‡πÅ‡∏ù‡∏î,...   \n",
       "4  [\", ‡∏ú‡∏ö.‡∏™‡∏™., \", ‡∏ô‡∏≥, ‡∏ó‡∏´‡∏≤‡∏£, ‡∏£‡∏±‡∏Å‡∏©‡∏≤, ‡∏û‡∏£‡∏∞‡∏≠‡∏á‡∏Ñ‡πå,  , ‡∏™‡∏ß...   \n",
       "\n",
       "                                      article_tokens  \n",
       "0  [‡∏ô‡∏≤‡∏¢, ‡∏ä‡∏π, ‡∏ß‡∏¥‡∏ó‡∏¢‡πå,  , ‡∏Å‡∏°‡∏•, ‡∏ß‡∏¥, ‡∏®‡∏¥‡∏©‡∏é‡πå,  , ‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤...  \n",
       "1  [‡πÅ‡∏ö‡∏á‡∏Å‡πå, ‡∏ã‡∏µ, ‡πÑ‡∏≠, ‡πÄ‡∏≠‡πá‡∏°, ‡∏ö‡∏µ,  , ‡∏ä‡∏µ‡πâ, ‡∏Å‡∏≤‡∏£‡∏ü‡∏∑‡πâ‡∏ô‡∏ü‡∏π, ‡πÄ...  \n",
       "2  [‡∏à‡∏≤‡∏Å, ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô, ‡∏Ç‡∏≠‡∏á, ‡∏ö‡∏µ‡∏ö‡∏µ‡∏ã‡∏µ,  , ‡∏≠‡∏≠‡∏™‡∏Å‡∏≤‡∏£‡πå,  , ‡∏û‡∏¥, ...  \n",
       "3  [‡πÄ‡∏≠‡πá‡∏°, ‡∏°‡∏≤,  , ‡∏•‡∏µ,  , ‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏°‡πà, ‡∏ä‡∏≤‡∏ß, ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©,  , ‡∏ß...  \n",
       "4  [‡πÄ‡∏°‡∏∑‡πà‡∏≠, ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà,  , 3,  , ‡∏ò.‡∏Ñ.,  , ‡∏ó‡∏µ‡πà, ‡∏°‡∏ì‡∏ë‡∏•, ‡∏û...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13877, 5)\n",
      "(2449, 5)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.15, random_state=42)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### featurize function\n",
    "- input is tokenized sentence (list of str)\n",
    "- output is feature dictionary `{feature: 1}` \n",
    "- bag-of-words, but binary value (not actual count, just existence)\n",
    "- use *unigram only* or *unigram & bigram*\n",
    "- use not only tokens, but also other features, e.g. text length\n",
    "\n",
    "~~~python\n",
    "['the','boy','love','the','dog'] \n",
    "-> {'LENGTH':5, 'the':1, 'boy':1, 'love':1, 'dog':1, 'the|boy':1, 'boy|love':1, 'love|the':1, 'the|dog':1}\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_unigram(tokens:list):\n",
    "    feat_dic = {}\n",
    "    for i, token in enumerate(tokens):\n",
    "        ## add unigram\n",
    "        feat_dic[token] = 1\n",
    "        ## add text length\n",
    "        feat_dic['LENGTH'] = len(tokens)\n",
    "    return feat_dic\n",
    "\n",
    "def featurize_bigram(tokens:list):\n",
    "    feat_dic = {}\n",
    "    for i, token in enumerate(tokens):\n",
    "        ## add unigram\n",
    "        feat_dic[token] = 1\n",
    "        ## add bigram\n",
    "        if i < len(tokens) - 1:\n",
    "            bigram = '|'.join(tokens[i:i+2]) # e.g. ‡∏â‡∏±‡∏ô|‡πÑ‡∏õ\n",
    "            feat_dic[bigram] = 1\n",
    "        ## add text length\n",
    "        feat_dic['text_length'] = len(tokens)\n",
    "    return feat_dic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all-in-one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import cla\n",
    "\n",
    "\n",
    "def train_predict(X_column_name, featurize_function_name, return_model=False):\n",
    "    ## make X : featurize each record as dictionary\n",
    "    X_train = train[X_column_name].apply(featurize_function_name)\n",
    "    X_test = test[X_column_name].apply(featurize_function_name)\n",
    "\n",
    "    ## make y\n",
    "    y_train = train['category']\n",
    "    y_test = test['category']\n",
    "\n",
    "    ## Instantiate DictVectorizer, LogisticRegression\n",
    "    pipe = Pipeline([\n",
    "        ('dv', DictVectorizer(sparse=True)),  ## feature dictionary -> vector\n",
    "        ('logreg', LogisticRegression(max_iter=200))\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    if return_model:\n",
    "        return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use `headline` + unigram feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        crime       0.57      0.58      0.57       295\n",
      "      economy       0.59      0.52      0.55       172\n",
      "    education       0.71      0.58      0.64       137\n",
      "entertainment       0.74      0.78      0.76       123\n",
      "      foreign       0.75      0.74      0.75       194\n",
      "        local       0.37      0.37      0.37       243\n",
      "     politics       0.80      0.83      0.81       475\n",
      "    publicize       0.76      0.81      0.78       230\n",
      "       region       0.59      0.63      0.61       384\n",
      "        sport       0.89      0.82      0.85       196\n",
      "\n",
      "     accuracy                           0.67      2449\n",
      "    macro avg       0.68      0.66      0.67      2449\n",
      " weighted avg       0.67      0.67      0.67      2449\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "train_predict('headline_tokens', featurize_unigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use `headline` + bigram feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        crime       0.62      0.63      0.62       295\n",
      "      economy       0.65      0.53      0.59       172\n",
      "    education       0.67      0.60      0.63       137\n",
      "entertainment       0.73      0.80      0.76       123\n",
      "      foreign       0.82      0.77      0.79       194\n",
      "        local       0.45      0.39      0.42       243\n",
      "     politics       0.80      0.85      0.83       475\n",
      "    publicize       0.79      0.84      0.81       230\n",
      "       region       0.61      0.68      0.64       384\n",
      "        sport       0.92      0.86      0.89       196\n",
      "\n",
      "     accuracy                           0.71      2449\n",
      "    macro avg       0.71      0.69      0.70      2449\n",
      " weighted avg       0.70      0.71      0.70      2449\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "train_predict('headline_tokens', featurize_bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use `article` + unigram feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        crime       0.70      0.66      0.68       295\n",
      "      economy       0.85      0.71      0.77       172\n",
      "    education       0.76      0.65      0.70       137\n",
      "entertainment       0.89      0.93      0.91       123\n",
      "      foreign       0.98      0.95      0.96       194\n",
      "        local       0.46      0.36      0.40       243\n",
      "     politics       0.84      0.88      0.86       475\n",
      "    publicize       0.72      0.85      0.78       230\n",
      "       region       0.66      0.74      0.70       384\n",
      "        sport       0.93      0.94      0.94       196\n",
      "\n",
      "     accuracy                           0.77      2449\n",
      "    macro avg       0.78      0.77      0.77      2449\n",
      " weighted avg       0.76      0.77      0.76      2449\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_predict('article_tokens', featurize_unigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use `article` + bigram feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        crime       0.70      0.61      0.65       295\n",
      "      economy       0.89      0.76      0.82       172\n",
      "    education       0.78      0.72      0.75       137\n",
      "entertainment       0.91      0.95      0.93       123\n",
      "      foreign       0.95      0.95      0.95       194\n",
      "        local       0.43      0.42      0.42       243\n",
      "     politics       0.90      0.86      0.88       475\n",
      "    publicize       0.88      0.86      0.87       230\n",
      "       region       0.64      0.80      0.71       384\n",
      "        sport       0.94      0.95      0.94       196\n",
      "\n",
      "     accuracy                           0.78      2449\n",
      "    macro avg       0.80      0.79      0.79      2449\n",
      " weighted avg       0.79      0.78      0.78      2449\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_predict('article_tokens', featurize_bigram, return_model=True) ## return model to check coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the score of the model using `article` and bigram feature is the best\n",
    "- `local` is relatively low score, while `sport` and `foreign` are very high "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check the coefficient of the model\n",
    "- coefficients show \"for which category, which words are important\" \n",
    "- `model` is a pipeline of `DictVectorizer` and `LogisticRegression`\n",
    "- feature names (vocabulary) are in `model.named_steps['dv'].get_feature_names_out()`\n",
    "- coefficients are in `model.named_steps['logreg'].coef_`, which is (`number of class` * `number of features`) array\n",
    "- class names are in `model.named_steps['logreg'].classes_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\\n</th>\n",
       "      <th>\\n|</th>\n",
       "      <th>\\n|</th>\n",
       "      <th>\\n|</th>\n",
       "      <th>\\n|</th>\n",
       "      <th>\\n|</th>\n",
       "      <th>\\n|</th>\n",
       "      <th>\\n|</th>\n",
       "      <th>\\n|</th>\n",
       "      <th>\\n|</th>\n",
       "      <th>...</th>\n",
       "      <th>ü§£ü§£ü§£</th>\n",
       "      <th>ü§£ü§£ü§£|</th>\n",
       "      <th>ü§©'</th>\n",
       "      <th>ü§©'|\\n</th>\n",
       "      <th>ü§≠</th>\n",
       "      <th>ü§≠|</th>\n",
       "      <th>ü¶Ö</th>\n",
       "      <th>ü¶Ö|</th>\n",
       "      <th>üßêüßêüßê'</th>\n",
       "      <th>üßêüßêüßê'|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>-0.149943</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>-0.026670</td>\n",
       "      <td>-0.014312</td>\n",
       "      <td>-0.005237</td>\n",
       "      <td>-0.010718</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>-0.000981</td>\n",
       "      <td>0.017418</td>\n",
       "      <td>-0.002446</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.000220</td>\n",
       "      <td>-0.000220</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economy</th>\n",
       "      <td>0.054815</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.301755</td>\n",
       "      <td>0.059787</td>\n",
       "      <td>0.006448</td>\n",
       "      <td>-0.003048</td>\n",
       "      <td>-0.000739</td>\n",
       "      <td>-0.001348</td>\n",
       "      <td>-0.006467</td>\n",
       "      <td>-0.000269</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000185</td>\n",
       "      <td>-0.000185</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>-0.000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>-0.537101</td>\n",
       "      <td>-0.069786</td>\n",
       "      <td>-0.015420</td>\n",
       "      <td>-0.009334</td>\n",
       "      <td>-0.005805</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>0.006637</td>\n",
       "      <td>-0.001226</td>\n",
       "      <td>-0.006746</td>\n",
       "      <td>-0.000263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000394</td>\n",
       "      <td>-0.000394</td>\n",
       "      <td>-0.000309</td>\n",
       "      <td>-0.000309</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertainment</th>\n",
       "      <td>0.317735</td>\n",
       "      <td>0.106225</td>\n",
       "      <td>0.044031</td>\n",
       "      <td>0.028689</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.012623</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>-0.000332</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006192</td>\n",
       "      <td>-0.006192</td>\n",
       "      <td>0.002921</td>\n",
       "      <td>0.002921</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.001344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreign</th>\n",
       "      <td>0.172769</td>\n",
       "      <td>-0.051582</td>\n",
       "      <td>-0.032828</td>\n",
       "      <td>-0.007985</td>\n",
       "      <td>-0.003734</td>\n",
       "      <td>-0.003294</td>\n",
       "      <td>-0.000809</td>\n",
       "      <td>-0.001029</td>\n",
       "      <td>-0.005080</td>\n",
       "      <td>-0.000262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000648</td>\n",
       "      <td>-0.000648</td>\n",
       "      <td>-0.000435</td>\n",
       "      <td>-0.000435</td>\n",
       "      <td>-0.000273</td>\n",
       "      <td>-0.000273</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local</th>\n",
       "      <td>0.038415</td>\n",
       "      <td>-0.029535</td>\n",
       "      <td>-0.033639</td>\n",
       "      <td>-0.006615</td>\n",
       "      <td>-0.006444</td>\n",
       "      <td>0.008666</td>\n",
       "      <td>-0.007228</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>-0.012510</td>\n",
       "      <td>0.005113</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000444</td>\n",
       "      <td>-0.000444</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>-0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politics</th>\n",
       "      <td>0.087388</td>\n",
       "      <td>-0.101622</td>\n",
       "      <td>-0.062854</td>\n",
       "      <td>-0.014392</td>\n",
       "      <td>-0.005324</td>\n",
       "      <td>-0.007038</td>\n",
       "      <td>-0.000874</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>-0.000334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>-0.000375</td>\n",
       "      <td>-0.000375</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>-0.000890</td>\n",
       "      <td>-0.000890</td>\n",
       "      <td>-0.000349</td>\n",
       "      <td>-0.000349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publicize</th>\n",
       "      <td>-0.213819</td>\n",
       "      <td>0.213898</td>\n",
       "      <td>-0.089111</td>\n",
       "      <td>-0.010234</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>0.010816</td>\n",
       "      <td>-0.000688</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>-0.005406</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>-0.000301</td>\n",
       "      <td>-0.000301</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>-0.000112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <td>0.013706</td>\n",
       "      <td>-0.094105</td>\n",
       "      <td>-0.062718</td>\n",
       "      <td>-0.017035</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-0.009043</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>-0.001398</td>\n",
       "      <td>0.016628</td>\n",
       "      <td>-0.002949</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000362</td>\n",
       "      <td>-0.000362</td>\n",
       "      <td>-0.000332</td>\n",
       "      <td>-0.000332</td>\n",
       "      <td>-0.000275</td>\n",
       "      <td>-0.000275</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>-0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sport</th>\n",
       "      <td>0.216035</td>\n",
       "      <td>0.017929</td>\n",
       "      <td>-0.022547</td>\n",
       "      <td>-0.008569</td>\n",
       "      <td>-0.003213</td>\n",
       "      <td>-0.002555</td>\n",
       "      <td>-0.000575</td>\n",
       "      <td>-0.000879</td>\n",
       "      <td>-0.004804</td>\n",
       "      <td>-0.000394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>-0.000369</td>\n",
       "      <td>-0.000369</td>\n",
       "      <td>-0.000269</td>\n",
       "      <td>-0.000269</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>-0.000124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 1081886 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     \\n      \\n|      \\n|      \\n|      \\n|      \\n|       \\\n",
       "crime         -0.149943  0.003958 -0.026670 -0.014312 -0.005237 -0.010718   \n",
       "economy        0.054815  0.004620  0.301755  0.059787  0.006448 -0.003048   \n",
       "education     -0.537101 -0.069786 -0.015420 -0.009334 -0.005805  0.003591   \n",
       "entertainment  0.317735  0.106225  0.044031  0.028689  0.016216  0.012623   \n",
       "foreign        0.172769 -0.051582 -0.032828 -0.007985 -0.003734 -0.003294   \n",
       "local          0.038415 -0.029535 -0.033639 -0.006615 -0.006444  0.008666   \n",
       "politics       0.087388 -0.101622 -0.062854 -0.014392 -0.005324 -0.007038   \n",
       "publicize     -0.213819  0.213898 -0.089111 -0.010234  0.006912  0.010816   \n",
       "region         0.013706 -0.094105 -0.062718 -0.017035  0.000180 -0.009043   \n",
       "sport          0.216035  0.017929 -0.022547 -0.008569 -0.003213 -0.002555   \n",
       "\n",
       "               \\n|        \\n|         \\n|          \\n|           ...  \\\n",
       "crime           0.002544   -0.000981     0.017418     -0.002446  ...   \n",
       "economy        -0.000739   -0.001348    -0.006467     -0.000269  ...   \n",
       "education       0.006637   -0.001226    -0.006746     -0.000263  ...   \n",
       "entertainment   0.002046   -0.000332     0.005296      0.002188  ...   \n",
       "foreign        -0.000809   -0.001029    -0.005080     -0.000262  ...   \n",
       "local          -0.007228    0.002891    -0.012510      0.005113  ...   \n",
       "politics       -0.000874   -0.000018     0.001672     -0.000334  ...   \n",
       "publicize      -0.000688    0.004319    -0.005406     -0.000385  ...   \n",
       "region         -0.000314   -0.001398     0.016628     -0.002949  ...   \n",
       "sport          -0.000575   -0.000879    -0.004804     -0.000394  ...   \n",
       "\n",
       "                    ü§£ü§£ü§£     ü§£ü§£ü§£|         ü§©'     ü§©'|\\n         ü§≠       ü§≠|   \\\n",
       "crime         -0.000258 -0.000258 -0.000230 -0.000230 -0.000220 -0.000220   \n",
       "economy       -0.000185 -0.000185 -0.000250 -0.000250 -0.000165 -0.000165   \n",
       "education     -0.000394 -0.000394 -0.000309 -0.000309 -0.000190 -0.000190   \n",
       "entertainment -0.006192 -0.006192  0.002921  0.002921  0.002208  0.002208   \n",
       "foreign       -0.000648 -0.000648 -0.000435 -0.000435 -0.000273 -0.000273   \n",
       "local         -0.000444 -0.000444 -0.000319 -0.000319 -0.000248 -0.000248   \n",
       "politics       0.008955  0.008955 -0.000375 -0.000375 -0.000411 -0.000411   \n",
       "publicize     -0.000168 -0.000168 -0.000301 -0.000301 -0.000157 -0.000157   \n",
       "region        -0.000362 -0.000362 -0.000332 -0.000332 -0.000275 -0.000275   \n",
       "sport         -0.000304 -0.000304 -0.000369 -0.000369 -0.000269 -0.000269   \n",
       "\n",
       "                      ü¶Ö       ü¶Ö|       üßêüßêüßê'    üßêüßêüßê'|   \n",
       "crime         -0.000161 -0.000161 -0.000128 -0.000128  \n",
       "economy       -0.000127 -0.000127 -0.000101 -0.000101  \n",
       "education     -0.000148 -0.000148 -0.000102 -0.000102  \n",
       "entertainment  0.002171  0.002171  0.001344  0.001344  \n",
       "foreign       -0.000223 -0.000223 -0.000148 -0.000148  \n",
       "local         -0.000213 -0.000213 -0.000139 -0.000139  \n",
       "politics      -0.000890 -0.000890 -0.000349 -0.000349  \n",
       "publicize     -0.000114 -0.000114 -0.000112 -0.000112  \n",
       "region        -0.000161 -0.000161 -0.000141 -0.000141  \n",
       "sport         -0.000135 -0.000135 -0.000124 -0.000124  \n",
       "\n",
       "[10 rows x 1081886 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = model.named_steps['logreg']\n",
    "dv = model.named_steps['dv']\n",
    "\n",
    "coef_df = pd.DataFrame(logreg.coef_, index=logreg.classes_, columns=dv.get_feature_names_out())\n",
    "coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "‡∏Ñ‡∏î‡∏µ                      0.482072\n",
       "‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ï‡∏≥‡∏£‡∏ß‡∏à‡πÅ‡∏´‡πà‡∏á‡∏ä‡∏≤‡∏ï‡∏¥    0.462208\n",
       " |‡∏≠‡∏≤‡∏¢‡∏∏                   0.456848\n",
       "‡∏™‡∏ô.                      0.429003\n",
       "‡∏ñ‡∏ô‡∏ô                      0.428496\n",
       "‡∏ï‡∏£.                      0.414659\n",
       "‡∏ï‡∏≥‡∏£‡∏ß‡∏à                    0.413153\n",
       "‡∏≠‡∏≤‡∏¢‡∏∏                     0.380555\n",
       "‡∏ú‡∏π‡πâ‡∏™‡∏∑‡πà‡∏≠‡∏Ç‡πà‡∏≤‡∏ß              0.374774\n",
       "‡∏ó‡∏£‡∏≤‡∏ö                     0.364511\n",
       "Name: crime, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## top 10 words for crime\n",
    "## 9 of 10 are unigram feature\n",
    "coef_df.loc['crime'].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "‡∏ó‡∏µ‡∏°           0.938355\n",
       "‡∏Å‡∏µ‡∏¨‡∏≤          0.682856\n",
       "‡∏Å‡∏≤‡∏£‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô    0.660912\n",
       " |\"           0.630376\n",
       "\"|            0.615295\n",
       "‡∏ó‡∏µ‡∏°|‡∏ä‡∏≤‡∏ï‡∏¥      0.578672\n",
       "‡∏®‡∏∂‡∏Å           0.575925\n",
       "‡∏ü‡∏∏‡∏ï‡∏ö‡∏≠‡∏•        0.570742\n",
       "‡∏ä‡∏≤‡∏ï‡∏¥          0.532676\n",
       "\"             0.530143\n",
       "Name: sport, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## top 10 words for sports\n",
    "coef_df.loc['sport'].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If remove stopwords/punctuations?\n",
    "- there are a lot of punctuation/stopwords in the result above\n",
    "- clean data and tokenize again \n",
    "- allowed token pattern is `[A-Za-z0-9‡∏Å-‡πô\\-\\.]`\n",
    "- not use bigram, because many words are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = thai_stopwords()\n",
    "\n",
    "def my_tokenize(text):\n",
    "    text = text.replace('\\\"', '') # remove double quotation\n",
    "    text = text.replace('\\'', '') # remove single quotation\n",
    "    tokens = word_tokenize(text, keep_whitespace=False)\n",
    "    tokens = [token for token in tokens if re.match(r'[A-Za-z0-9‡∏Å-‡πô\\-\\.]+', token)]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        crime       0.70      0.66      0.68       295\n",
      "      economy       0.85      0.71      0.77       172\n",
      "    education       0.76      0.65      0.70       137\n",
      "entertainment       0.89      0.93      0.91       123\n",
      "      foreign       0.98      0.95      0.96       194\n",
      "        local       0.46      0.36      0.40       243\n",
      "     politics       0.84      0.88      0.86       475\n",
      "    publicize       0.72      0.85      0.78       230\n",
      "       region       0.66      0.74      0.70       384\n",
      "        sport       0.93      0.94      0.94       196\n",
      "\n",
      "     accuracy                           0.77      2449\n",
      "    macro avg       0.78      0.77      0.77      2449\n",
      " weighted avg       0.76      0.77      0.76      2449\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['article_tokens'] = df.article.apply(my_tokenize)\n",
    "train_predict('article_tokens', featurize_unigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The result is almost the same as the previous uniigram model\n",
    "- Removing stopwords/punctuation did not help to improve the model in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Improvement\n",
    "\n",
    "- To change tokenizing method may be less helpful\n",
    "- Must modify featurize function\n",
    "    - each category has some specific characteristics except for word itself\n",
    "    - e.g. `economy` may contain many digit characters -> try to use the feature `digit_char_ratio` \n",
    "- show confusion matrix in oreder to detect which label is often misunderstood for which label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
